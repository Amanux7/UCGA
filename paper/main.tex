\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{float}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{booktabs}

\geometry{margin=1in}

% ======================
% CODE STYLE
% ======================

\definecolor{codegray}{gray}{0.95}

\lstset{
backgroundcolor=\color{codegray},
basicstyle=\ttfamily\small,
breaklines=true,
language=Python
}

% ======================
% TITLE
% ======================

\title{
Unified Cognitive Graph Architecture (UCGA): \\
A Graph-Native Cognitive Framework for Artificial General Intelligence, AI Agents, and Multimodal Systems
}

\author{
Aman Singh \\
Founder, UCGA Research Initiative
}

\date{2026}

\begin{document}

\maketitle

% ======================
% ABSTRACT
% ======================

\begin{abstract}

This paper introduces the Unified Cognitive Graph Architecture (UCGA), a novel graph-native cognitive framework designed to address fundamental limitations of traditional neural architectures in reasoning, memory integration, and adaptive intelligence. UCGA models intelligence as recursive interaction between specialised cognitive nodes connected through adaptive weighted edges, incorporating persistent attention-based memory, self-evaluation, and conditional error correction.

We present the architecture, mathematical formulation, and a fully differentiable PyTorch implementation comprising nine cognitive node types, three input encoders, and a persistent memory system. Experimental validation on standard benchmarks demonstrates the framework's learning capability: UCGA achieves \textbf{90.5\%} test accuracy on AG News text classification and \textbf{60.0\%} on CIFAR-10 image classification, establishing its viability across both NLP and computer vision domains.

A comprehensive test suite of 43 unit and integration tests validates architectural correctness. We further outline a roadmap for scaling UCGA toward full artificial general intelligence capability.

\end{abstract}

% ======================
% INTRODUCTION
% ======================

\section{Introduction}

Artificial intelligence systems today rely heavily on sequential neural architectures such as feedforward networks and transformer models~\cite{vaswani2017attention}. While these systems achieve strong performance in specific domains, they remain fundamentally limited in recursive reasoning, persistent memory integration, and adaptive cognitive restructuring.

Biological intelligence operates differently. Cognitive processes emerge from dynamic interaction between specialised brain regions forming a graph-like structure~\cite{baars1988cognitive}. Each region performs a distinct function---perception, memory retrieval, reasoning, planning, evaluation---while communicating through adaptive connections.

This paper introduces the Unified Cognitive Graph Architecture (UCGA), which models intelligence as a dynamic cognitive graph. Unlike conventional architectures, UCGA explicitly separates cognitive functions into distinct, trainable nodes that interact through a recursive refinement loop, supported by persistent attention-based memory.

Key contributions include:
\begin{itemize}
\item A graph-native cognitive architecture with nine specialised differentiable nodes
\item A recursive refinement loop with self-evaluation and conditional error correction
\item Persistent attention-based memory with least-used-slot write mechanisms
\item Demonstration of effective learning on real-world benchmarks (AG News, CIFAR-10)
\item A fully open-source, pip-installable implementation with 43 unit tests
\end{itemize}

% ======================
% PROBLEM STATEMENT
% ======================

\section{Problem Statement}

Current architectures face several key limitations:

\begin{itemize}
\item \textbf{Static architecture structure}: Layer-based models cannot dynamically restructure their processing pipeline based on input complexity.
\item \textbf{Limited recursive reasoning}: Feedforward architectures lack the ability to iteratively refine outputs through multiple reasoning passes.
\item \textbf{Weak persistent memory}: Standard architectures discard inter-sample context; attention over context windows provides only transient memory.
\item \textbf{No self-evaluation}: Traditional models lack intrinsic mechanisms to assess confidence and trigger error correction.
\end{itemize}

UCGA addresses these limitations by modeling intelligence as a recursive cognitive graph with explicit evaluation and correction mechanisms.

% ======================
% ARCHITECTURE
% ======================

\section{UCGA Architecture}

UCGA defines intelligence as:

\begin{equation}
G = (V, E, W, S, M)
\end{equation}

Where:

\begin{itemize}
\item $V = \{v_1, \ldots, v_9\}$: Cognitive nodes (Perception, Memory, Reasoning, Planning, Evaluation, Correction, Balancer, Output)
\item $E \subseteq V \times V$: Directed edges representing information flow
\item $W: E \to \mathbb{R}^{d \times d}$: Learnable weight matrices
\item $S: V \to \mathbb{R}^d$: Cognitive state vectors
\item $M \in \mathbb{R}^{K \times d}$: Persistent memory bank with $K$ slots
\end{itemize}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{figure1_ucga_architecture.png}
\caption{Unified Cognitive Graph Architecture. Nine cognitive nodes interact through a directed graph, processing input through perception, memory retrieval, multi-step reasoning, planning, self-evaluation, conditional correction, stream balancing, and output generation.}
\end{figure}

% ======================
% RECURSIVE LOOP
% ======================

\section{Recursive Cognitive Refinement}

UCGA operates through recursive refinement cycles. At each cognitive timestep $t \in \{1, \ldots, T\}$, the full node graph is traversed:

\begin{enumerate}
\item \textbf{Perceive}: Project raw input into cognitive space via learned projection
\item \textbf{Retrieve}: Attend to persistent memory using the percept as query
\item \textbf{Reason}: Iteratively refine the combined signal over $K$ reasoning sub-steps
\item \textbf{Plan}: Generate sub-goal embeddings from the reasoning output
\item \textbf{Evaluate}: Compute confidence $c \in [0, 1]$ via sigmoid gating
\item \textbf{Correct}: If $c < \tau$, apply gated residual correction
\item \textbf{Balance}: Dynamically weight reasoning, correction, and memory streams via learned softmax gates
\item \textbf{Output}: Project through a residual-enhanced output head
\item \textbf{Write}: Store the balanced state in persistent memory for future retrieval
\end{enumerate}

The balanced output feeds back as input for the next cognitive timestep, enabling iterative refinement.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{figure2_cognitive_loop.png}
\caption{Recursive Cognitive Refinement Loop. Each iteration traverses the full cognitive graph, with the balanced output feeding back as input for subsequent refinement.}
\end{figure}

% ======================
% MATHEMATICS
% ======================

\section{Mathematical Formulation}

\subsection{State Update Rule}

Each cognitive node applies a non-saturating state update:

\begin{equation}
v_i(t+1) = \text{LayerNorm}\left(\text{GELU}\left(W_i \sum_j v_j(t) + b_i\right)\right)
\end{equation}

The use of GELU activation with layer normalisation prevents gradient vanishing through deep cognitive loops, a critical improvement over the initial $\tanh$-based formulation which exhibited gradient saturation across $\geq 7$ stacked nodes.

\subsection{Attention-Based Memory Read}

Memory retrieval uses scaled dot-product attention:

\begin{equation}
\text{Read}(q, M) = \text{softmax}\left(\frac{q W_Q \cdot M^\top}{\sqrt{d}}\right) M
\end{equation}

\subsection{Self-Evaluation}

The evaluation node produces a confidence scalar:

\begin{equation}
c = \sigma(W_c \cdot [v_\text{plan}; v_\text{reason}] + b_c) \in [0, 1]
\end{equation}

\subsection{Conditional Correction}

When $c < \tau$ (threshold), a gated residual correction is applied:

\begin{equation}
v_\text{corrected} = g \odot v_\text{correction} + (1 - g) \odot v_\text{plan}
\end{equation}

where $g = \sigma(W_g [v_\text{plan}; v_\text{eval}])$ is a learned gate.

\subsection{Stream Balancing}

The balancer computes dynamic weights over $N$ cognitive streams:

\begin{equation}
\alpha = \text{softmax}(W_\alpha \cdot \text{concat}(v_1, \ldots, v_N))
\end{equation}

\begin{equation}
v_\text{balanced} = \sum_{i=1}^N \alpha_i \cdot v_i
\end{equation}

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{figure3_math_model.png}
\caption{Mathematical interaction model showing the flow of information through cognitive nodes, with GELU+LayerNorm activation, attention-based memory, and gated correction.}
\end{figure}

% ======================
% IMPLEMENTATION
% ======================

\section{Prototype Implementation}

UCGA has been implemented as a fully differentiable PyTorch framework. The implementation comprises:

\begin{itemize}
\item \textbf{9 cognitive node types}: Each implemented as an \texttt{nn.Module} subclass
\item \textbf{3 input encoders}: \texttt{VectorEncoder} (MLP), \texttt{TextEncoder} (multi-scale 1D-CNN), \texttt{ImageEncoder} (lightweight CNN)
\item \textbf{Persistent memory}: Attention-based read with least-used-slot writes
\item \textbf{Package structure}: Pip-installable via \texttt{pyproject.toml}
\item \textbf{43 unit/integration tests}: All passing, covering nodes, memory, encoders, and end-to-end training
\end{itemize}

\begin{lstlisting}[caption={CognitiveNode base class with GELU+LayerNorm activation}]
class CognitiveNode(nn.Module):
    def __init__(self, input_dim, state_dim):
        super().__init__()
        self.W = nn.Linear(input_dim, state_dim, bias=False)
        self.b = nn.Parameter(torch.zeros(state_dim))
        self.activation = nn.GELU()
        self.norm = nn.LayerNorm(state_dim)
        self.register_buffer("state", torch.zeros(1, state_dim))

    def forward(self, inputs):
        aggregated = torch.stack(inputs, dim=0).sum(dim=0)
        self.state = self.norm(
            self.activation(self.W(aggregated) + self.b)
        )
        return self.state
\end{lstlisting}

% ======================
% EXPERIMENTS
% ======================

\section{Experimental Validation}

We validate UCGA on three categories of experiments: synthetic reasoning tasks, real-world text classification, and real-world image classification.

\subsection{Synthetic Reasoning}

Initial experiments on synthetic vector reasoning (predicting $y = \tanh(W_\text{true} \cdot [a; b] + c)$ from random vectors $a, b$) confirmed:
\begin{itemize}
\item Stable convergence across 50 training epochs
\item Loss decreasing from 1.0 to 0.5 (MSE)
\item Correct gradient flow through all 9 cognitive nodes
\end{itemize}

\subsection{AG News Text Classification}

AG News~\cite{zhang2015character} is a standard 4-class news topic classification benchmark with 120,000 training and 7,600 test samples. Classes: World, Sports, Business, Sci/Tech.

\textbf{Configuration}: Bag-of-words features (8,000-word vocabulary) $\to$ VectorEncoder $\to$ UCGAModel (state\_dim=128, 1 cognitive step, 1 reasoning step).

\begin{table}[H]
\centering
\caption{AG News training progression}
\begin{tabular}{@{}cccc@{}}
\toprule
Epoch & Train Accuracy & Test Accuracy & Loss \\
\midrule
1 & 71.3\% & 85.2\% & 0.800 \\
3 & 95.8\% & 89.4\% & 0.130 \\
5 & 98.4\% & 90.2\% & 0.040 \\
10 & 99.5\% & \textbf{90.5\%} & 0.010 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{CIFAR-10 Image Classification}

CIFAR-10~\cite{krizhevsky2009learning} is a standard 10-class image classification benchmark with 50,000 training and 10,000 test images of size $32 \times 32$.

\textbf{Configuration}: ImageEncoder (3-layer CNN with batch normalisation) $\to$ UCGAModel (state\_dim=128, 2 cognitive steps, 2 reasoning steps). Data augmentation: random crop + horizontal flip.

\begin{table}[H]
\centering
\caption{CIFAR-10 training progression}
\begin{tabular}{@{}cccc@{}}
\toprule
Epoch & Train Accuracy & Test Accuracy & Loss \\
\midrule
1 & 29.0\% & 32.5\% & 1.82 \\
5 & 47.2\% & 45.8\% & 1.42 \\
10 & 56.1\% & 53.2\% & 1.21 \\
20 & 68.3\% & \textbf{60.0\%} & 0.91 \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Summary of Results}

\begin{table}[H]
\centering
\caption{UCGA benchmark results across modalities}
\begin{tabular}{@{}llccc@{}}
\toprule
Benchmark & Modality & Classes & Test Accuracy & Encoder \\
\midrule
AG News & Text & 4 & \textbf{90.5\%} & VectorEncoder (BOW) \\
CIFAR-10 & Image & 10 & \textbf{60.0\%} & ImageEncoder (CNN) \\
Synthetic & Vector & --- & converged & VectorEncoder \\
\bottomrule
\end{tabular}
\end{table}

% ======================
% COMPARISON
% ======================

\section{Comparison with Traditional Architectures}

\begin{table}[H]
\centering
\caption{Qualitative comparison of UCGA with standard architectures}
\begin{tabular}{@{}lccc@{}}
\toprule
Feature & MLP/CNN & Transformer & UCGA \\
\midrule
Recursive reasoning & \texttimes & Limited & \checkmark \\
Persistent memory & \texttimes & Context window & \checkmark \\
Self-evaluation & \texttimes & \texttimes & \checkmark \\
Error correction & \texttimes & \texttimes & \checkmark \\
Dynamic stream balancing & \texttimes & \texttimes & \checkmark \\
Modular cognitive nodes & \texttimes & \texttimes & \checkmark \\
Multimodal by design & \texttimes & Limited & \checkmark \\
\bottomrule
\end{tabular}
\end{table}

UCGA differs fundamentally from layer-based architectures by modelling intelligence as a specialised cognitive graph. While a standard 3-layer CNN achieves approximately 65\% on CIFAR-10 and a bag-of-words SVM achieves approximately 88\% on AG News, UCGA achieves competitive results while also providing intrinsic self-evaluation, persistent memory, and recursive reasoning capabilities that these baselines lack.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{figure4_comparison.png}
\caption{UCGA vs Traditional Architectures: structural comparison}
\end{figure}

% ======================
% ARCHITECTURE INSIGHTS
% ======================

\section{Architecture Insights}

Several key insights emerged during development:

\begin{enumerate}
\item \textbf{Activation function choice is critical}: The original $\tanh$ activation caused complete gradient vanishing when stacked across 7+ cognitive nodes. Replacing with GELU + LayerNorm resolved this entirely, enabling learning on real data.

\item \textbf{Residual connections in the output node}: Adding a pre-activation residual bypass in the OutputNode prevented information bottlenecks at the final classification layer.

\item \textbf{Feature representation matters}: For text classification, bag-of-words features significantly outperformed learned token embeddings through the cognitive loop (90.5\% vs 25\% accuracy), suggesting the UCGA loop excels at learning decision boundaries over pre-extracted features.

\item \textbf{Cognitive step count}: A single cognitive step ($T=1$) was sufficient for classification tasks, while multiple steps showed benefits in synthetic reasoning tasks.

\item \textbf{Gradient management}: Persistent memory writes must detach stored content from the computation graph to prevent gradient accumulation across training iterations.
\end{enumerate}

% ======================
% CURRENT STATUS
% ======================

\section{Current Development Status}

UCGA currently includes:

\begin{itemize}
\item Complete architecture definition with 9 cognitive node types
\item Full mathematical formulation with GELU + LayerNorm state updates
\item Differentiable PyTorch implementation (pip-installable)
\item Real-world benchmark validation (AG News 90.5\%, CIFAR-10 60\%)
\item Synthetic training and experiment infrastructure
\item Persistent attention-based memory with differentiable read/write
\item Cognitive agent wrapper for interactive inference
\item 43-test suite covering all components
\item arXiv-ready research paper and documentation
\end{itemize}

% ======================
% FUTURE WORK
% ======================

\section{Future Work and Roadmap}

Future research will focus on:

\begin{itemize}
\item \textbf{Transformer-based reasoning}: Replacing the current MLP-based reasoning node with multi-head self-attention for richer compositional reasoning
\item \textbf{Learned text encoding}: Developing a more powerful text encoder that can learn representations end-to-end through the cognitive loop
\item \textbf{Multimodal fusion}: Integrating vision, language, and audio streams within the same cognitive graph
\item \textbf{Autonomous reasoning agents}: Building agents that use UCGA for multi-step planning and decision-making
\item \textbf{Dynamic graph topology}: Allowing the cognitive graph structure itself to adapt during training
\item \textbf{Self-improving cognitive evolution}: Enabling the architecture to grow new nodes and connections based on task demands
\item \textbf{Scaling experiments}: Training on larger datasets (ImageNet, full text corpora) with GPU cluster resources
\end{itemize}

These developments aim to scale UCGA toward full artificial general intelligence capability.

% ======================
% LIMITATIONS
% ======================

\section{Current Limitations}

\begin{itemize}
\item \textbf{Text encoding}: The current TextEncoder (1D-CNN) does not learn effective representations through the cognitive loop for classification; BOW features were required as a workaround
\item \textbf{Scale}: Experiments were conducted on standard benchmarks; large-scale training has not yet been explored
\item \textbf{Cognitive steps}: Multiple cognitive steps provided limited benefit on classification tasks; their value for complex reasoning tasks remains to be validated at scale
\item \textbf{Memory capacity}: The persistent memory bank uses a fixed number of slots; dynamic allocation would improve efficiency
\item \textbf{Single-task training}: Each benchmark was trained independently; cross-task transfer and continual learning have not been evaluated
\end{itemize}

% ======================
% AI ASSISTANCE DISCLOSURE
% ======================

\section{AI Assistance and Development Tools}

During the development of the Unified Cognitive Graph Architecture (UCGA), modern AI-assisted research and development tools were utilised to support ideation, implementation structuring, documentation refinement, and prototype development.

Specifically, large language models including Gemini (Google) and GPT-5.2 (OpenAI) were used as cognitive assistance tools to help accelerate:

\begin{itemize}
\item Research structuring and conceptual clarification
\item Mathematical formulation refinement
\item Prototype implementation guidance
\item Documentation and technical writing support
\item Development workflow planning
\end{itemize}

These tools functioned strictly as research assistants and development aids. All architectural design decisions, conceptual framework definition, and research direction were conceived, evaluated, and directed by the author.

The Unified Cognitive Graph Architecture itself is an original architectural framework proposed and developed by the author.

% ======================
% CONCLUSION
% ======================

\section{Conclusion}

UCGA introduces a new paradigm for artificial intelligence architecture based on cognitive graph interaction. Our experiments demonstrate that the framework can learn effectively from real-world data, achieving 90.5\% accuracy on AG News text classification and 60.0\% on CIFAR-10 image classification.

Key architectural insights---particularly the necessity of non-saturating activations (GELU + LayerNorm) and residual connections for gradient flow through deep cognitive loops---were validated through iterative experimentation. The framework's intrinsic self-evaluation, persistent memory, and conditional error correction mechanisms distinguish it from conventional neural architectures.

The fully open-source implementation, comprising 30+ source files, a 43-test suite, and pip-installable packaging, provides a foundation for future research into graph-native cognitive architectures for artificial general intelligence.

% ======================
% ACKNOWLEDGMENTS
% ======================

\section{Acknowledgments}

The author acknowledges the use of modern AI-assisted development tools including Gemini (Google) and GPT-5.2 (OpenAI) for providing technical assistance during the research and development process.

The author also acknowledges the broader open-source research community whose foundational work in neural networks, graph neural networks, and cognitive architectures has contributed to the scientific ecosystem enabling this research.

% ======================
% REFERENCES
% ======================

\bibliographystyle{plain}
\bibliography{references}

% ======================
% END
% ======================

\end{document}
